#!/usr/bin/env python3
"""
barkRelay PoC - Voice to Text Transcription using faster_whisper
Proof of Concept for real-time voice transcription and AI agent relay
"""

import os
import sys
import time
import wave
import tempfile
import threading
from datetime import datetime
from pathlib import Path

try:
    import pyaudio
    import numpy as np
    from faster_whisper import WhisperModel
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
    print("\nğŸ“¦ ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install faster-whisper pyaudio numpy")
    sys.exit(1)

class BarkRelayPoC:
    def __init__(self, model_size="base", device="cpu", compute_type="int8"):
        """
        éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        
        Args:
            model_size: Whisperãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚º (tiny, base, small, medium, large)
            device: ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ (cpu, cuda)
            compute_type: è¨ˆç®—ã‚¿ã‚¤ãƒ— (int8, float16, float32)
        """
        self.model_size = model_size
        self.device = device
        self.compute_type = compute_type
        self.model = None
        
        # éŸ³å£°éŒ²éŸ³è¨­å®šï¼ˆé«˜å“è³ªåŒ–ï¼‰
        self.CHUNK = 4096  # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’å¤§ããï¼ˆãƒã‚¤ã‚ºè»½æ¸›ï¼‰
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000  # Whisperæ¨å¥¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
        self.SILENCE_THRESHOLD = 3  # 3ç§’é–“ç„¡éŸ³ã§åˆ†æå®Ÿè¡Œ
        
        # éŸ³å£°æ¤œå‡ºè¨­å®šï¼ˆæ„Ÿåº¦èª¿æ•´ï¼‰
        self.VOLUME_THRESHOLD = 300  # éŸ³å£°æ¤œå‡ºã®é–¾å€¤ã‚’ä¸‹ã’ã‚‹ï¼ˆã‚ˆã‚Šæ•æ„Ÿã«ï¼‰
        self.silence_duration = 0  # ç„¡éŸ³ç¶™ç¶šæ™‚é–“
        self.is_speaking = False  # ç¾åœ¨è©±ã—ã¦ã„ã‚‹ã‹ã®çŠ¶æ…‹
        
        # é€£ç¶šéŒ²éŸ³ç”¨
        self.continuous_frames = []  # é€£ç¶šã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿
        self.last_voice_time = time.time()  # æœ€å¾Œã«éŸ³å£°ã‚’æ¤œå‡ºã—ãŸæ™‚é–“
        
        # å…¨æ–‡ä¿å­˜
        self.full_transcription = []  # å…¨ã¦ã®æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜
        
        self.is_recording = False
        self.audio = None
        
        print("ğŸ¤ barkRelay PoC - Voice to Text Transcription")
        print("ğŸš€ Apple Silicon M4æœ€é©åŒ–å¯¾å¿œç‰ˆ")
        print("=" * 50)
        
    def initialize_model(self):
        """Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆApple Silicon GPUå¯¾å¿œï¼‰"""
        print(f"ğŸ“Š Whisperãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­... (ã‚µã‚¤ã‚º: {self.model_size}, ãƒ‡ãƒã‚¤ã‚¹: {self.device})")
        
        # Apple Silicon (M1/M2/M3/M4) GPUæ¤œå‡º
        if self.device == "auto":
            import platform
            if platform.processor() == 'arm' and platform.system() == 'Darwin':
                # Apple Silicon Mac
                print("ğŸ Apple Silicon Macæ¤œå‡º - Metal Performance Shadersã‚’ä½¿ç”¨")
                try:
                    # Apple Siliconæœ€é©åŒ–è¨­å®š
                    self.model = WhisperModel(
                        self.model_size,
                        device="cpu",  # Apple Siliconã§ã¯CPUãŒæœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹
                        compute_type="int8",  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–
                        cpu_threads=8  # M4ã®é«˜æ€§èƒ½ã‚³ã‚¢æ•°
                    )
                    print("âœ… Apple Siliconæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–å®Œäº†")
                    return True
                except Exception as e:
                    print(f"âŒ Apple Siliconæœ€é©åŒ–å¤±æ•—: {e}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®CPU
            self.device = "cpu"
            self.compute_type = "int8"
        
        try:
            # ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆæœŸåŒ–
            if self.device == "cuda":
                # NVIDIA GPU
                self.model = WhisperModel(
                    self.model_size,
                    device="cuda",
                    compute_type="float16"
                )
                print("âœ… CUDA GPUåˆæœŸåŒ–å®Œäº†")
            else:
                # CPU (Apple Siliconã‚’å«ã‚€)
                cpu_threads = 8 if platform.processor() == 'arm' else 4
                self.model = WhisperModel(
                    self.model_size,
                    device="cpu",
                    compute_type=self.compute_type,
                    cpu_threads=cpu_threads
                )
                print(f"âœ… CPUåˆæœŸåŒ–å®Œäº† (ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {cpu_threads})")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if self.device != "cpu":
                print("ğŸ”„ CPUãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...")
                try:
                    self.model = WhisperModel(
                        self.model_size, 
                        device="cpu", 
                        compute_type="int8",
                        cpu_threads=4
                    )
                    print("âœ… CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–å®Œäº†")
                    return True
                except Exception as e2:
                    print(f"âŒ CPUãƒ¢ãƒ¼ãƒ‰ã§ã‚‚åˆæœŸåŒ–å¤±æ•—: {e2}")
                    return False
            return False
    
    def initialize_audio(self):
        """éŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã®åˆæœŸåŒ–"""
        try:
            self.audio = pyaudio.PyAudio()
            
            # åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
            print("\nğŸ”Š åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:")
            for i in range(self.audio.get_device_count()):
                info = self.audio.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    print(f"  {i}: {info['name']}")
            
            return True
        except Exception as e:
            print(f"âŒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def detect_silence(self, audio_data):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç„¡éŸ³ã‚’æ¤œå‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # NumPyé…åˆ—ã«å¤‰æ›
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        
        # RMSï¼ˆRoot Mean Squareï¼‰ã‚’è¨ˆç®—
        rms = np.sqrt(np.mean(audio_array.astype(np.float32) ** 2))
        
        # ãƒ”ãƒ¼ã‚¯å€¤ã‚‚è€ƒæ…®
        peak = np.max(np.abs(audio_array))
        
        # RMSã¨ãƒ”ãƒ¼ã‚¯ã®ä¸¡æ–¹ã§åˆ¤å®šï¼ˆã‚ˆã‚Šæ­£ç¢ºãªéŸ³å£°æ¤œå‡ºï¼‰
        is_silent = (rms < self.VOLUME_THRESHOLD) and (peak < self.VOLUME_THRESHOLD * 3)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if hasattr(self, 'debug_audio') and self.debug_audio:
            print(f"ğŸ”Š RMS: {rms:.1f}, Peak: {peak:.1f}, Silent: {is_silent}")
        
        return is_silent
    
    def record_continuous_audio(self):
        """é€£ç¶šéŸ³å£°éŒ²éŸ³ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ¤œå‡ºï¼‰"""
        stream = self.audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            frames_per_buffer=self.CHUNK
        )
        
        print("ğŸ™ï¸ éŸ³å£°å…¥åŠ›å¾…æ©Ÿä¸­...")
        
        while self.is_recording:
            try:
                data = stream.read(self.CHUNK, exception_on_overflow=False)
                current_time = time.time()
                
                # éŸ³å£°æ¤œå‡º
                if not self.detect_silence(data):
                    # éŸ³å£°æ¤œå‡ºæ™‚
                    if not self.is_speaking:
                        # éŸ³å£°æ¤œå‡ºé–‹å§‹
                        print("\n" + "="*50)
                        print("ğŸ¤ éŸ³å£°æ¤œå‡º - éŒ²éŸ³é–‹å§‹")
                        print("="*50)
                        self.is_speaking = True
                        self.continuous_frames = []
                    
                    self.continuous_frames.append(data)
                    self.last_voice_time = current_time
                    
                else:
                    # ç„¡éŸ³æ™‚
                    if self.is_speaking:
                        # ç™ºè©±ä¸­ã‹ã‚‰ã®ç„¡éŸ³
                        self.silence_duration = current_time - self.last_voice_time
                        
                        if self.silence_duration >= self.SILENCE_THRESHOLD:
                            # 3ç§’ä»¥ä¸Šç„¡éŸ³ â†’ ç™ºè©±çµ‚äº†ã¨ã—ã¦å‡¦ç†
                            print("-"*50)
                            print(f"ğŸ”‡ ç™ºè©±çµ‚äº†æ¤œå‡º (ç„¡éŸ³: {self.silence_duration:.1f}ç§’)")
                            print("-"*50)
                            
                            # è“„ç©ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                            audio_file = self.save_continuous_frames()
                            if audio_file:
                                yield audio_file
                            
                            # çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
                            self.is_speaking = False
                            self.continuous_frames = []
                            self.silence_duration = 0
                    
            except Exception as e:
                print(f"âš ï¸ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
                break
        
        stream.stop_stream()
        stream.close()
    
    def save_continuous_frames(self):
        """é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not self.continuous_frames:
            return None
            
        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                wf = wave.open(temp_file.name, 'wb')
                wf.setnchannels(self.CHANNELS)
                wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))
                wf.setframerate(self.RATE)
                wf.writeframes(b''.join(self.continuous_frames))
                wf.close()
                
                return temp_file.name
        except Exception as e:
            print(f"âŒ éŸ³å£°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def transcribe_audio(self, audio_file_path):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆé«˜ç²¾åº¦è¨­å®šï¼‰"""
        try:
            # ã‚ˆã‚Šé«˜ç²¾åº¦ãªè¨­å®šã§æ–‡å­—èµ·ã“ã—
            segments, info = self.model.transcribe(
                audio_file_path,
                beam_size=5,  # ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚µã‚¤ã‚º
                language="ja",  # æ—¥æœ¬èªã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
                condition_on_previous_text=False,  # å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã«ä¾å­˜ã—ãªã„
                temperature=0.0,  # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„çµæœã‚’é¸æŠ
                compression_ratio_threshold=2.4,  # åœ§ç¸®ç‡é–¾å€¤
                log_prob_threshold=-1.0,  # å¯¾æ•°ç¢ºç‡é–¾å€¤
                no_speech_threshold=0.6,  # ç„¡éŸ³åˆ¤å®šé–¾å€¤
                word_timestamps=True,  # å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                initial_prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚"  # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            )
            
            # çµæœã‚’ã¾ã¨ã‚ã‚‹ï¼ˆã‚ˆã‚Šè©³ç´°ãªå‡¦ç†ï¼‰
            full_text = ""
            total_segments = 0
            
            for segment in segments:
                segment_text = segment.text.strip()
                if segment_text:  # ç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                    # ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆå¹³å‡å¯¾æ•°ç¢ºç‡ï¼‰
                    if hasattr(segment, 'avg_logprob') and segment.avg_logprob > -0.8:
                        full_text += segment_text + " "
                        total_segments += 1
                    else:
                        # ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯æ³¨è¨˜ï¼ˆãƒ‡ãƒãƒƒã‚°æ™‚ã®ã¿è¡¨ç¤ºï¼‰
                        if hasattr(self, 'debug_audio') and self.debug_audio:
                            print(f"âš ï¸ ä½ä¿¡é ¼åº¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {segment_text} (ä¿¡é ¼åº¦: {segment.avg_logprob:.3f})")
                        full_text += segment_text + " "  # æ³¨è¨˜ãªã—ã§è¿½åŠ 
                        total_segments += 1
            
            result = full_text.strip()
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¯é™ã‹ã«ï¼ˆå¿…è¦æ™‚ã®ã¿è¡¨ç¤ºï¼‰
            if hasattr(self, 'debug_audio') and self.debug_audio and result:
                print(f"ğŸ“Š èªè­˜çµæœ: {total_segments}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ, ä¿¡é ¼åº¦æƒ…å ±ä»˜ã")
            
            return result
            
        except Exception as e:
            print(f"âŒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(audio_file_path)
            except:
                pass
    
    def format_output(self, text):
        """å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        if text:
            print(f"[{timestamp}] ğŸ“ {text}")
            self.full_transcription.append(text)  # å…¨æ–‡ã«è¿½åŠ 
            return text
        else:
            print(f"[{timestamp}] ğŸ”‡ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return None
    
    def analyze_conversation(self):
        """ä¼šè©±åˆ†æã‚’å®Ÿè¡Œï¼ˆç„¡éŸ³æ™‚ï¼‰"""
        if not self.full_transcription:
            return
            
        print("\n" + "="*60)
        print("ğŸ“Š ä¼šè©±åˆ†æå®Ÿè¡Œä¸­...")
        
        # å…¨æ–‡ã‚’çµåˆ
        full_text = " ".join(self.full_transcription)
        
        print(f"ğŸ“ˆ ç·ç™ºè©±æ•°: {len(self.full_transcription)}å›")
        print(f"ğŸ“ ç·æ–‡å­—æ•°: {len(full_text)}æ–‡å­—")
        
        # ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        keywords = self.extract_keywords(full_text)
        if keywords:
            print(f"ğŸ”¤ ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords[:5])}")
        
        print("="*60 + "\n")
    
    def extract_keywords(self, text):
        """ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        # æ—¥æœ¬èªã®ä¸€èˆ¬çš„ãªã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰
        stop_words = {'ã§ã™', 'ã¾ã™', 'ã§ã‚ã‚‹', 'ã«ã¤ã„ã¦', 'ã¨ã—ã¦', 'ã¨ã„ã†', 
                     'ã“ã¨', 'ã‚‚ã®', 'ã¨ã“ã‚', 'ãŸã‚', 'ã‚ˆã†', 'ãã†', 'ã‹ã‚‰',
                     'ã®ã§', 'ã‘ã‚Œã©', 'ã§ã‚‚', 'ã—ã‹ã—', 'ãã‚Œã§', 'ãã—ã¦'}
        
        # å˜èªã‚’åˆ†å‰²ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        words = []
        current_word = ""
        for char in text:
            if char.isalnum():
                current_word += char
            else:
                if current_word and len(current_word) > 1:
                    words.append(current_word)
                current_word = ""
        
        # é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
        word_count = {}
        for word in words:
            if word not in stop_words and len(word) > 1:
                word_count[word] = word_count.get(word, 0) + 1
        
        # é »åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        return sorted(word_count.keys(), key=lambda x: word_count[x], reverse=True)
    
    def show_full_transcription(self):
        """å…¨æ–‡è¡¨ç¤º"""
        if not self.full_transcription:
            print("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
            
        print("\n" + "="*60)
        print("ğŸ“„ å…¨æ–‡è¡¨ç¤º")
        print("="*60)
        
        full_text = " ".join(self.full_transcription)
        print(full_text)
        
        print("\n" + "-"*60)
        print(f"ğŸ“ˆ çµ±è¨ˆ: {len(self.full_transcription)}å›ã®ç™ºè©±, {len(full_text)}æ–‡å­—")
        print("="*60 + "\n")
    
    def start_transcription(self):
        """æ–‡å­—èµ·ã“ã—ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        if not self.initialize_model():
            return
        
        if not self.initialize_audio():
            return
        
        print("\nğŸš€ éŸ³å£°æ–‡å­—èµ·ã“ã—é–‹å§‹")
        print("ğŸ’¡ è©±ã™ã¨è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã™ï¼ˆ3ç§’é–“ç„¡éŸ³ã§åŒºåˆ‡ã‚Šï¼‰")
        print("Ctrl+C ã§çµ‚äº†")
        print("-" * 50)
        
        self.is_recording = True
        
        try:
            # é€£ç¶šéŸ³å£°éŒ²éŸ³ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨
            for audio_file in self.record_continuous_audio():
                if audio_file:
                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                    print("ğŸ”„ æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­...")
                    print("-"*50)
                    transcribed_text = self.transcribe_audio(audio_file)
                    
                    if transcribed_text and transcribed_text.strip():
                        # çµæœå‡ºåŠ›
                        result = self.format_output(transcribed_text)
                        
                        # AI Agenté€£æºãƒã‚¤ãƒ³ãƒˆï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
                        if result:
                            self.send_to_ai_agent(result)
                        
                        print("="*50)
                        print("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†")
                        print("="*50)
                    else:
                        timestamp = datetime.now().strftime("%H:%M:%S")
                        print(f"[{timestamp}] ğŸ”‡ éŸ³å£°èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        print("="*50)
                        print("âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—")
                        print("="*50)
                
                # æ¬¡ã®ç™ºè©±ã‚’å¾…æ©Ÿ
                print("â³ æ¬¡ã®ç™ºè©±ã‚’å¾…æ©Ÿä¸­...")
                print()
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
            self.is_recording = False
        
        except Exception as e:
            print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        
        finally:
            self.cleanup()
    
    def send_to_ai_agent(self, text):
        """AI Agentã¸ã®é€ä¿¡ï¼ˆæœªå®Ÿè£…ï¼‰"""
        # TODO: REST API ã¾ãŸã¯ WebSocket ã§AI Agentã«é€ä¿¡
        print(f"ğŸ¤– [AI Agent] æ–‡å­—èµ·ã“ã—çµæœå—ä¿¡: {text[:50]}...")
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.audio:
            self.audio.terminate()
        
        # æœ€çµ‚çš„ãªå…¨æ–‡è¡¨ç¤ºã¨åˆ†æ
        self.show_full_transcription()
        
        # æœ€çµ‚åˆ†æã‚’å®Ÿè¡Œ
        if self.full_transcription:
            print("\nğŸ” æœ€çµ‚ä¼šè©±åˆ†æ:")
            self.analyze_conversation()
        
        print("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="barkRelay PoC - Voice to Text Transcription")
    parser.add_argument("--model", choices=["tiny", "base", "small", "medium", "large"], 
                       default="base", help="Whisperãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: base)")
    parser.add_argument("--device", choices=["auto", "cpu", "cuda"], default="auto", 
                       help="ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: auto - Apple Siliconè‡ªå‹•æ¤œå‡º)")
    parser.add_argument("--silence-threshold", type=int, default=3,
                       help="åˆ†æå®Ÿè¡Œã™ã‚‹ç„¡éŸ³æ™‚é–“ï¼ˆç§’ï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3)")
    parser.add_argument("--volume-threshold", type=int, default=300,
                       help="éŸ³å£°æ¤œå‡ºã®éŸ³é‡é–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 300)")
    parser.add_argument("--debug", action="store_true",
                       help="ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º")
    parser.add_argument("--model-improve", action="store_true",
                       help="ã‚ˆã‚Šé«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä½¿ç”¨")
    
    args = parser.parse_args()
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
    import platform
    print(f"ğŸ–¥ï¸  ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {sys.platform}")
    print(f"ğŸ Python: {sys.version.split()[0]}")
    print(f"ğŸ”§ ãƒ—ãƒ­ã‚»ãƒƒã‚µ: {platform.processor()}")
    print(f"ğŸ“± ãƒã‚·ãƒ³: {platform.machine()}")
    
    # Apple Siliconæ¤œå‡º
    if platform.processor() == 'arm' and platform.system() == 'Darwin':
        print("ğŸ Apple Silicon Macæ¤œå‡º - æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ä½¿ç”¨")
    elif args.device == "cuda":
        print("ğŸ® CUDA GPUæŒ‡å®š")
    else:
        print("ğŸ’» CPUä½¿ç”¨")
    
    # PoCã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    # Apple Siliconæœ€é©åŒ–
    if args.device == "auto" and platform.processor() == 'arm' and platform.system() == 'Darwin':
        compute_type = "int8"  # Apple Siliconç”¨æœ€é©åŒ–
    elif args.device == "cuda":
        compute_type = "float16"  # NVIDIA GPUç”¨
    else:
        compute_type = "int8"  # ãã®ä»–CPUç”¨
    
    bark_relay = BarkRelayPoC(
        model_size=args.model,
        device=args.device,
        compute_type=compute_type
    )
    
    bark_relay.SILENCE_THRESHOLD = args.silence_threshold
    bark_relay.VOLUME_THRESHOLD = args.volume_threshold
    bark_relay.debug_audio = args.debug
    
    # é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«è¨­å®š
    if args.model_improve:
        print("ğŸ¯ é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")
        bark_relay.model_improve_mode = True
    
    # æ–‡å­—èµ·ã“ã—é–‹å§‹
    bark_relay.start_transcription()

if __name__ == "__main__":
    main()