#!/usr/bin/env python3
"""
barkRelay Real-time - Real-time Voice Transcription using faster-whisper
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import time
import pyaudio
import numpy as np
import threading
import queue
from datetime import datetime
from faster_whisper import WhisperModel

try:
    import pyaudio
    import numpy as np
    from faster_whisper import WhisperModel
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
    print("\nğŸ“¦ ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install faster-whisper pyaudio numpy")
    sys.exit(1)

class RealtimeTranscriber:
    def __init__(self, model_size="base", device="auto"):
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        """
        self.model_size = model_size
        self.device = device
        self.model = None
        
        # éŸ³å£°è¨­å®š (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ç”¨)
        self.CHUNK = 2048  # å¤§ããªãƒãƒ£ãƒ³ã‚¯ã§ã‚ˆã‚Šå®‰å®šã—ãŸå‡¦ç†
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.BUFFER_SECONDS = 2  # 2ç§’ãƒãƒƒãƒ•ã‚¡ï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
        
        # éŸ³å£°æ¤œå‡ºè¨­å®š
        self.VOLUME_THRESHOLD = 200  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã«èª¿æ•´
        self.MIN_AUDIO_LENGTH = 0.5  # æœ€å°éŸ³å£°é•·ï¼ˆç§’ï¼‰
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ç”¨
        self.audio_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.is_recording = False
        self.audio = None
        
        # çµæœç®¡ç†
        self.partial_results = []
        self.confirmed_results = []
        
        print("ğŸ¤ barkRelay Real-time - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—")
        print("ğŸš€ Apple Silicon M4æœ€é©åŒ–å¯¾å¿œç‰ˆ")
        print("=" * 60)
    
    def initialize_model(self):
        """Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆApple Siliconæœ€é©åŒ–ï¼‰"""
        print(f"ğŸ“Š Whisperãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­... (ã‚µã‚¤ã‚º: {self.model_size})")
        
        import platform
        
        try:
            if self.device == "auto" and platform.processor() == 'arm' and platform.system() == 'Darwin':
                # Apple Siliconæœ€é©åŒ–
                self.model = WhisperModel(
                    self.model_size,
                    device="cpu",
                    compute_type="int8",
                    cpu_threads=8  # M4ã®é«˜æ€§èƒ½ã‚³ã‚¢
                )
                print("âœ… Apple Siliconæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–å®Œäº†")
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
                device = "cpu" if self.device == "auto" else self.device
                self.model = WhisperModel(
                    self.model_size,
                    device=device,
                    compute_type="int8" if device == "cpu" else "float16"
                )
                print(f"âœ… {device.upper()}ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–å®Œäº†")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def initialize_audio(self, device_index=None):
        """éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã®åˆæœŸåŒ–"""
        try:
            self.audio = pyaudio.PyAudio()
            
            # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
            input_devices = []
            print("\nğŸ”Š åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:")
            for i in range(self.audio.get_device_count()):
                info = self.audio.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    input_devices.append((i, info['name']))
                    print(f"  {i}: {info['name']}")
            
            # ãƒ‡ãƒã‚¤ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¤œè¨¼
            if device_index is not None:
                if device_index < 0 or device_index >= self.audio.get_device_count():
                    print(f"âŒ ç„¡åŠ¹ãªãƒ‡ãƒã‚¤ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {device_index}")
                    return False
                
                device_info = self.audio.get_device_info_by_index(device_index)
                if device_info['maxInputChannels'] == 0:
                    print(f"âŒ ãƒ‡ãƒã‚¤ã‚¹ {device_index} ã¯éŸ³å£°å…¥åŠ›ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“")
                    return False
                
                print(f"âœ… é¸æŠã•ã‚ŒãŸãƒ‡ãƒã‚¤ã‚¹: {device_index} - {device_info['name']}")
                self.selected_device = device_index
            else:
                # ãƒ‡ãƒã‚¤ã‚¹æœªæŒ‡å®šã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                self.selected_device = None
                print("ğŸ’¡ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨")
            
            return True
        except Exception as e:
            print(f"âŒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def detect_voice(self, audio_data):
        """éŸ³å£°æ¤œå‡º"""
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        rms = np.sqrt(np.mean(audio_array.astype(np.float32) ** 2))
        return rms > self.VOLUME_THRESHOLD
    
    def audio_capture_worker(self):
        """éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®š
        stream_config = {
            'format': self.FORMAT,
            'channels': self.CHANNELS,
            'rate': self.RATE,
            'input': True,
            'frames_per_buffer': self.CHUNK
        }
        
        # ãƒ‡ãƒã‚¤ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ 
        if hasattr(self, 'selected_device') and self.selected_device is not None:
            stream_config['input_device_index'] = self.selected_device
        
        stream = self.audio.open(**stream_config)
        
        print("ğŸ™ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹...")
        
        frames = []
        silence_count = 0
        is_speaking = False
        
        while self.is_recording:
            try:
                data = stream.read(self.CHUNK, exception_on_overflow=False)
                
                # éŸ³å£°æ¤œå‡º
                has_voice = self.detect_voice(data)
                
                if has_voice:
                    if not is_speaking:
                        print("ğŸ¤ éŸ³å£°æ¤œå‡º", end="", flush=True)
                        is_speaking = True
                        frames = []
                    
                    frames.append(data)
                    silence_count = 0
                    print(".", end="", flush=True)  # éŒ²éŸ³ä¸­ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿
                    
                else:
                    if is_speaking:
                        silence_count += 1
                        frames.append(data)  # ç„¡éŸ³éƒ¨åˆ†ã‚‚å°‘ã—å«ã‚ã‚‹
                        
                        # ååˆ†ãªç„¡éŸ³æœŸé–“ã§å‡¦ç†é–‹å§‹
                        if silence_count >= 15:  # ç´„0.5ç§’ã®ç„¡éŸ³
                            print(" å‡¦ç†ä¸­...")
                            
                            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                            if len(frames) >= 8:  # æœ€å°é•·ãƒã‚§ãƒƒã‚¯
                                audio_data = b''.join(frames)
                                self.audio_queue.put(audio_data)
                            
                            # ãƒªã‚»ãƒƒãƒˆ
                            frames = []
                            silence_count = 0
                            is_speaking = False
                            
            except Exception as e:
                print(f"âš ï¸ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼: {e}")
                break
        
        stream.stop_stream()
        stream.close()
    
    def transcription_worker(self):
        """æ–‡å­—èµ·ã“ã—ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        while self.is_recording or not self.audio_queue.empty():
            try:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                audio_data = self.audio_queue.get(timeout=1)
                
                # NumPyé…åˆ—ã«å¤‰æ›
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                audio_float = audio_array.astype(np.float32) / 32768.0
                
                # éŸ³å£°é•·ãƒã‚§ãƒƒã‚¯
                duration = len(audio_float) / self.RATE
                if duration < self.MIN_AUDIO_LENGTH:
                    continue
                
                # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                segments, info = self.model.transcribe(
                    audio_float,
                    beam_size=3,  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã«è»½é‡åŒ–
                    language="ja",
                    temperature=0.0,
                    condition_on_previous_text=False,
                    initial_prompt="æ­£ç¢ºã«æ—¥æœ¬èªã§æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚"
                )
                
                # çµæœã‚’å‡¦ç†
                full_text = ""
                for segment in segments:
                    text = segment.text.strip()
                    if text:
                        full_text += text + " "
                
                if full_text.strip():
                    # çµæœã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    self.result_queue.put(full_text.strip())
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def display_worker(self):
        """çµæœè¡¨ç¤ºãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        while self.is_recording or not self.result_queue.empty():
            try:
                # çµæœã‚’å–å¾—
                result = self.result_queue.get(timeout=0.1)
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§è¡¨ç¤º
                timestamp = datetime.now().strftime("%H:%M:%S")
                print(f"\n[{timestamp}] ğŸ“ {result}")
                
                # çµæœã‚’ä¿å­˜
                self.confirmed_results.append(result)
                
                # AI Agenté€£æºãƒã‚¤ãƒ³ãƒˆ
                self.send_to_ai_agent(result)
                
                print("â³ æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿä¸­...", end="", flush=True)
                
            except queue.Empty:
                continue
    
    def send_to_ai_agent(self, text):
        """AI Agentã¸ã®é€ä¿¡ï¼ˆæœªå®Ÿè£…ï¼‰"""
        print(f"\nğŸ¤– [AI Agent] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµæœ: {text[:30]}...")
    
    def start_realtime_transcription(self, device_index=None):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹"""
        if not self.initialize_model():
            return
        
        if not self.initialize_audio(device_index):
            return
        
        print("\nğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹")
        print("ğŸ’¡ è©±ã™ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã™")
        print("Ctrl+C ã§çµ‚äº†")
        print("-" * 60)
        
        self.is_recording = True
        
        # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        capture_thread = threading.Thread(target=self.audio_capture_worker)
        capture_thread.daemon = True
        capture_thread.start()
        
        # æ–‡å­—èµ·ã“ã—ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        transcription_thread = threading.Thread(target=self.transcription_worker)
        transcription_thread.daemon = True
        transcription_thread.start()
        
        try:
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§çµæœè¡¨ç¤º
            self.display_worker()
            
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢ä¸­...")
            self.is_recording = False
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿ
            capture_thread.join(timeout=2)
            transcription_thread.join(timeout=2)
            
        finally:
            self.cleanup()
    
    def show_session_summary(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„è¡¨ç¤º"""
        if not self.confirmed_results:
            print("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("\n" + "="*60)
        print("ğŸ“„ ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„")
        print("="*60)
        
        full_text = " ".join(self.confirmed_results)
        print(full_text)
        
        print("\n" + "-"*60)
        print(f"ğŸ“Š çµ±è¨ˆ: {len(self.confirmed_results)}å›ã®ç™ºè©±, {len(full_text)}æ–‡å­—")
        print("="*60 + "\n")
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.audio:
            self.audio.terminate()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„è¡¨ç¤º
        self.show_session_summary()
        
        print("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    import platform
    
    parser = argparse.ArgumentParser(description="barkRelay Real-time - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—")
    parser.add_argument("--model", choices=["tiny", "base", "small", "medium", "large"], 
                       default="base", help="Whisperãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: base)")
    parser.add_argument("--compute-device", choices=["auto", "cpu", "cuda"], default="auto", 
                       help="ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: auto)")
    parser.add_argument("--volume-threshold", type=int, default=200,
                       help="éŸ³å£°æ¤œå‡ºã®éŸ³é‡é–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 200)")
    parser.add_argument("--audio-device", type=int, default=None,
                       help="ä½¿ç”¨ã™ã‚‹éŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå·")
    parser.add_argument("--list-devices", action="store_true",
                       help="åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤ºã—ã¦çµ‚äº†")
    
    args = parser.parse_args()
    
    # ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
    if args.list_devices:
        try:
            audio = pyaudio.PyAudio()
            print("ğŸ”Š åˆ©ç”¨å¯èƒ½ãªéŸ³å£°å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:")
            for i in range(audio.get_device_count()):
                info = audio.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    print(f"  {i}: {info['name']}")
            audio.terminate()
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
    print(f"ğŸ–¥ï¸  ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {sys.platform}")
    print(f"ğŸ Python: {sys.version.split()[0]}")
    print(f"ğŸ”§ ãƒ—ãƒ­ã‚»ãƒƒã‚µ: {platform.processor()}")
    print(f"ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹")
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    transcriber = RealtimeTranscriber(
        model_size=args.model,
        device=args.compute_device
    )
    
    transcriber.VOLUME_THRESHOLD = args.volume_threshold
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹
    transcriber.start_realtime_transcription(device_index=args.audio_device)

if __name__ == "__main__":
    main()